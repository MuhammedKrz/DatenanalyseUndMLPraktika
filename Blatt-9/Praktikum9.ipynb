{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Aufgabe 1 (5P)",
   "id": "415fc8f3e51dfd31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## a)\n",
    "Nutzen Sie vom Datensatz „pvtest.csv“ die Werte 'Edaily','Dci','Dcp','Dcu','Temp1','hour‘ und erstellen Sie einen DataFrame\n",
    "als Zeitreihe, ähnlich wie unten abgebildet. Auf Grundlage dieser Daten soll der Energieertrag Dcp immer in 5 Minuten in\n",
    "der Zukunft prognostiziert werden. (0.5P)\n",
    "\n",
    "<img src='images/1a.png' width=400>"
   ],
   "id": "ac523b11404d02c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T18:34:26.435673300Z",
     "start_time": "2026-01-21T18:34:26.318442800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_1 = pd.read_csv('pvtest.csv')\n",
    "df_1['Time'] = pd.to_datetime(df_1['Time'], format='%d.%m.%y %H:%M')\n",
    "df_1['hour'] = df_1['Time'].dt.hour\n",
    "df_1 = df_1.set_index('Time')\n",
    "\n",
    "columns = ['Edaily','Dci','Dcp','Dcu','Temp1','hour']\n",
    "df_1 = df_1[columns].copy()\n",
    "df_1.sort_values(by=\"Time\", inplace=True)\n",
    "\n",
    "print(df_1.loc['2021-01-26 16:25:00':'2021-01-26 17:40:00'])\n",
    "df_1.shape"
   ],
   "id": "18900b6042d4de35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Edaily       Dci  Dcp  Dcu  Temp1  hour\n",
      "Time                                                        \n",
      "2021-01-26 16:25:00   3.108  0.192504  113  587   14.0    16\n",
      "2021-01-26 16:30:00   3.122  0.111913   62  554   14.0    16\n",
      "2021-01-26 16:35:00   3.130  0.053846   28  520   14.0    16\n",
      "2021-01-26 16:40:00   3.137  0.041176   21  510   14.0    16\n",
      "2021-01-26 16:45:00   3.141  0.024283   11  453   14.0    16\n",
      "2021-01-26 16:50:00   3.144  0.000000    0  271   14.0    16\n",
      "2021-01-26 16:55:00   3.145  0.000000    0  257   13.0    16\n",
      "2021-01-26 17:00:00   3.145  0.000000    0  251   12.0    17\n",
      "2021-01-26 17:05:00   3.145  0.000000    0  250   12.0    17\n",
      "2021-01-26 17:10:00   3.145  0.000000    0   37    1.0    17\n",
      "2021-01-26 17:15:00   3.145  0.000000    0    0    0.0    17\n",
      "2021-01-26 17:20:00   3.145  0.000000    0    0    0.0    17\n",
      "2021-01-26 17:25:00   3.145  0.000000    0    0    0.0    17\n",
      "2021-01-26 17:35:00   3.145  0.000000    0    0    0.0    17\n",
      "2021-01-26 17:40:00   3.145  0.000000    0    0    0.0    17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3545, 6)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## b)\n",
    "Teilen Sie die Daten sinnvoll in Lern-und Testdatensatz auf, so dass die zeitlichen Reihenfolgen bestehen bleiben ! (0.5P)"
   ],
   "id": "f5dffa7d70ab2be7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T18:34:26.466410700Z",
     "start_time": "2026-01-21T18:34:26.450514900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df_1\n",
    "y = df_1[['Dcp']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)"
   ],
   "id": "1f61c0bc58734ba",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## c)\n",
    "Standardisieren Sie die Daten mit dem Standardscaler und restrukturieren Sie die Zeitreihe in einzelne Datenfenster, so dass\n",
    "Sie aus allen vorhandenen 6 Features aus den letzten drei Stunden immer jeweils den Energieertrag für die nächsten 5\n",
    "Minuten vorhersagen können. (1,5P)"
   ],
   "id": "dfbb2e554831f52d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T18:34:26.491600400Z",
     "start_time": "2026-01-21T18:34:26.468409600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# standardize training data\n",
    "scaler_x = StandardScaler()\n",
    "\n",
    "# teaching (anlernen) and training\n",
    "x_train_std = scaler_x.fit_transform(x_train)\n",
    "x_test_std = scaler_x.transform(x_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_std = scaler_y.fit_transform(y_train)\n",
    "y_test_std = scaler_y.transform(y_test)\n",
    "\n",
    "print(x_train_std.shape, y_train_std.shape)\n",
    "\n",
    "# Needs to be changed\n",
    "window = 12 * 3\n",
    "\n",
    "horizon = 1\n",
    "\n",
    "# 6 Features\n",
    "indicators = 6\n",
    "\n",
    "def restructure_data(X, y, window, horizon):\n",
    "    # lists in order to define the timestamps and related target variables\n",
    "    X_, y_ = [], []\n",
    "    # new range of the index for new matrices\n",
    "    idx_range = range(len(X) - (window + horizon))\n",
    "    for idx in idx_range:\n",
    "        # cutting out matrices\n",
    "        X_.append(X[idx:idx+window])\n",
    "        # slice [idx: idx+window] (search y-value)\n",
    "        y_.append(y[idx+window+horizon])\n",
    "    # parsing values to numpy arrays\n",
    "    X_ = np.array(X_)\n",
    "    y_ = np.array(y_)\n",
    "    return X_, y_\n",
    "\n",
    "# matrix (m,n) m rows and n columns\n",
    "x_train, y_train = restructure_data(x_train_std,y_train_std,window,horizon)\n",
    "x_test, y_test = restructure_data(x_test_std,y_test_std,window,horizon)"
   ],
   "id": "2681b70fc4214369",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2836, 6) (2836, 1)\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# d)\n",
    "Definieren und kompilieren Sie jetzt ein passendes Modell in Keras, welches mind. eine LSTM-Layer nutzt und DropoutLayer einfügt, um „Überanpassung“ zu verhindern. (1P)"
   ],
   "id": "d286171a44a9da9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T18:34:26.716208Z",
     "start_time": "2026-01-21T18:34:26.506601400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (LSTM, Dense, Bidirectional, Dropout)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units=16, return_sequences=True, dropout=0.2),\n",
    "input_shape=(window, indicators)))\n",
    "model.add(LSTM(units=32, dropout=0.2))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
    "model.summary()"
   ],
   "id": "187e2863c602df83",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammed Korkmaz\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_3\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_3 (\u001B[38;5;33mBidirectional\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m36\u001B[0m, \u001B[38;5;34m32\u001B[0m)         │         \u001B[38;5;34m2,944\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m8,320\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m1,056\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m12,353\u001B[0m (48.25 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,353</span> (48.25 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m12,353\u001B[0m (48.25 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,353</span> (48.25 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## e)\n",
    "Trainieren Sie das Modell mit allen Lerndaten über mind. 100 Epochen, nutzen Sie ggf. auch callbacks, um den Lernprozess\n",
    "zu verkürzen. Verbessern Sie Ihr Training und Ihre Modellarchitektur so lange, bis Sie einen Mean absolute Error von mind.\n",
    "50 erzielen! (1P)"
   ],
   "id": "4f7658cc2d7e9e99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T18:34:35.554042200Z",
     "start_time": "2026-01-21T18:34:26.722652100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import (EarlyStopping, ModelCheckpoint)\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', patience=2)\n",
    "check = ModelCheckpoint(filepath='consumption_power_model.h5',monitor='val_loss', save_best_only=True)\n",
    "history = model.fit(x_train, y_train,\n",
    "epochs=100, batch_size=128,\n",
    "validation_data=(x_test, y_test),\n",
    "callbacks=[early, check])"
   ],
   "id": "5ea29e3339dc8f2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.8060 - mae: 0.5510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 41ms/step - loss: 0.6171 - mae: 0.4615 - val_loss: 0.0326 - val_mae: 0.0967\n",
      "Epoch 2/100\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.3721 - mae: 0.3537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 0.3365 - mae: 0.3344 - val_loss: 0.0275 - val_mae: 0.0841\n",
      "Epoch 3/100\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.2381 - mae: 0.2845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.2551 - mae: 0.2885 - val_loss: 0.0270 - val_mae: 0.0830\n",
      "Epoch 4/100\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.2627 - mae: 0.2854 - val_loss: 0.0290 - val_mae: 0.0701\n",
      "Epoch 5/100\n",
      "\u001B[1m21/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.2307 - mae: 0.2669"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.2444 - mae: 0.2711 - val_loss: 0.0265 - val_mae: 0.0600\n",
      "Epoch 6/100\n",
      "\u001B[1m19/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.2414 - mae: 0.2741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 0.2469 - mae: 0.2714 - val_loss: 0.0264 - val_mae: 0.0619\n",
      "Epoch 7/100\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.2260 - mae: 0.2622 - val_loss: 0.0292 - val_mae: 0.0652\n",
      "Epoch 8/100\n",
      "\u001B[1m20/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.1855 - mae: 0.2497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 0.2127 - mae: 0.2561 - val_loss: 0.0244 - val_mae: 0.0599\n",
      "Epoch 9/100\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.2180 - mae: 0.2477 - val_loss: 0.0284 - val_mae: 0.0691\n",
      "Epoch 10/100\n",
      "\u001B[1m19/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.1893 - mae: 0.2366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 0.1846 - mae: 0.2364 - val_loss: 0.0244 - val_mae: 0.0566\n",
      "Epoch 11/100\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.1935 - mae: 0.2362 - val_loss: 0.0258 - val_mae: 0.0582\n",
      "Epoch 12/100\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.1876 - mae: 0.2341 - val_loss: 0.0276 - val_mae: 0.0589\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T18:34:36.089502900Z",
     "start_time": "2026-01-21T18:34:35.576071500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('consumption_power_model.h5',compile=False)\n",
    "y_true = y_test[window+horizon:]\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)"
   ],
   "id": "53e932572647cb27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m21/21\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T18:34:36.685275600Z",
     "start_time": "2026-01-21T18:34:36.120579700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae_model = mean_absolute_error(y_true, y_pred_inv)\n",
    "print('mae, model predictions {:.3f}'.format(mae_model))"
   ],
   "id": "b2d6d01546659364",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [635, 672]",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[70]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m mean_absolute_error\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m mae_model = \u001B[43mmean_absolute_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred_inv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mmae, model predictions \u001B[39m\u001B[38;5;132;01m{:.3f}\u001B[39;00m\u001B[33m'\u001B[39m.format(mae_model))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    213\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    214\u001B[39m         skip_parameter_validation=(\n\u001B[32m    215\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    216\u001B[39m         )\n\u001B[32m    217\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    224\u001B[39m     msg = re.sub(\n\u001B[32m    225\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    226\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    227\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    228\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:284\u001B[39m, in \u001B[36mmean_absolute_error\u001B[39m\u001B[34m(y_true, y_pred, sample_weight, multioutput)\u001B[39m\n\u001B[32m    228\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Mean absolute error regression loss.\u001B[39;00m\n\u001B[32m    229\u001B[39m \n\u001B[32m    230\u001B[39m \u001B[33;03mThe mean absolute error is a non-negative floating point value, where best value\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    279\u001B[39m \u001B[33;03m0.85...\u001B[39;00m\n\u001B[32m    280\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    281\u001B[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001B[32m    283\u001B[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001B[32m--> \u001B[39m\u001B[32m284\u001B[39m     \u001B[43m_check_reg_targets_with_floating_dtype\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\n\u001B[32m    286\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    287\u001B[39m )\n\u001B[32m    289\u001B[39m output_errors = _average(\n\u001B[32m    290\u001B[39m     xp.abs(y_pred - y_true), weights=sample_weight, axis=\u001B[32m0\u001B[39m, xp=xp\n\u001B[32m    291\u001B[39m )\n\u001B[32m    292\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(multioutput, \u001B[38;5;28mstr\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:209\u001B[39m, in \u001B[36m_check_reg_targets_with_floating_dtype\u001B[39m\u001B[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001B[39m\n\u001B[32m    160\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Ensures y_true, y_pred, and sample_weight correspond to same regression task.\u001B[39;00m\n\u001B[32m    161\u001B[39m \n\u001B[32m    162\u001B[39m \u001B[33;03mExtends `_check_reg_targets` by automatically selecting a suitable floating-point\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    205\u001B[39m \u001B[33;03m    correct keyword.\u001B[39;00m\n\u001B[32m    206\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    207\u001B[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001B[32m--> \u001B[39m\u001B[32m209\u001B[39m y_type, y_true, y_pred, sample_weight, multioutput = \u001B[43m_check_reg_targets\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[43m    \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\n\u001B[32m    211\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    213\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m y_type, y_true, y_pred, sample_weight, multioutput\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:114\u001B[39m, in \u001B[36m_check_reg_targets\u001B[39m\u001B[34m(y_true, y_pred, sample_weight, multioutput, dtype, xp)\u001B[39m\n\u001B[32m     63\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Check that y_true, y_pred and sample_weight belong to the same regression task.\u001B[39;00m\n\u001B[32m     64\u001B[39m \n\u001B[32m     65\u001B[39m \u001B[33;03mTo reduce redundancy when calling `_find_matching_floating_dtype`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    110\u001B[39m \u001B[33;03m    correct keyword.\u001B[39;00m\n\u001B[32m    111\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    112\u001B[39m xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    115\u001B[39m y_true = check_array(y_true, ensure_2d=\u001B[38;5;28;01mFalse\u001B[39;00m, dtype=dtype)\n\u001B[32m    116\u001B[39m y_pred = check_array(y_pred, ensure_2d=\u001B[38;5;28;01mFalse\u001B[39;00m, dtype=dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:473\u001B[39m, in \u001B[36mcheck_consistent_length\u001B[39m\u001B[34m(*arrays)\u001B[39m\n\u001B[32m    471\u001B[39m lengths = [_num_samples(X) \u001B[38;5;28;01mfor\u001B[39;00m X \u001B[38;5;129;01min\u001B[39;00m arrays \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[32m    472\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(lengths)) > \u001B[32m1\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m473\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    474\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    475\u001B[39m         % [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[32m    476\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Found input variables with inconsistent numbers of samples: [635, 672]"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# f)\n",
    "Visualisieren Sie Ihre Prognoseergebnisse, so ähnlich wie unten angegeben im Vergleich gemessener Daten mit\n",
    "prognostizierten Werten! (0.5P)\n",
    "\n",
    "<img src=\"images/1f.png\" width=900>"
   ],
   "id": "73529d7f0bbe85d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(y_true, color='blue')\n",
    "plt.plot(y_pred, color='red')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ],
   "id": "79e91d3d8d59ef3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
